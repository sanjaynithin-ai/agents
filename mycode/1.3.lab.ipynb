{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key not set\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key exists and begins gsk_\n"
     ]
    }
   ],
   "source": [
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")\n",
    "\n",
    "llama_model = \"llama3.2\"\n",
    "gemini_model = \"gemini-2.0-flash\"\n",
    "deepseek_model = \"deepseek-r1-distill-qwen-7b\"\n",
    "groq_model = \"meta-llama/llama-4-scout-17b-16e-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    "    api_key=google_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"../1_foundations/me/Profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "sanjay.nithin19@gmail.com\n",
      "www.linkedin.com/in/sanjay-\n",
      "nithin-6794471b8 (LinkedIn)\n",
      "sanjaynithin.tech (Portfolio)\n",
      "sanjaynithin.hashnode.dev (Blog)\n",
      "github.com/SanjayNithin2002\n",
      "(Personal)\n",
      "Top Skills\n",
      "Authorization\n",
      "WebSocket\n",
      "Socket.io\n",
      "Languages\n",
      "English (Native or Bilingual)\n",
      "Japanese (Elementary)\n",
      "Tamil (Native or Bilingual)\n",
      "Certifications\n",
      "Amazon Web Services Cloud\n",
      "Practitioner\n",
      "Design Thinking\n",
      "WebSocket Fundamentals with\n",
      "Socket.io\n",
      "Applied Data Science\n",
      "Publications\n",
      "Performance Analysis of a\n",
      "Micromodel-based Multinomial\n",
      "Classifier\n",
      "Sanjay Nithin\n",
      "Software Engineer @ AirIndia || Full Stack Developer || AWS Cloud\n",
      "Practitioner\n",
      "Vellore, Tamil Nadu, India\n",
      "Summary\n",
      "Driven by a passion for technology, I started programming at 16.\n",
      "Over the years, I've created exciting projects, from smart bots to\n",
      "complex systems. I'm eager to leverage my skills to make a real\n",
      "impact and help shape the future of technology together.\n",
      "Experience\n",
      "Air India Limited\n",
      "Software Developer\n",
      "August 2024 - Present (11 months)\n",
      "Kochi, Kerala, India\n",
      "eSomein Consultancy Pvt Ltd\n",
      "Software Developer\n",
      "May 2023 - September 2023 (5 months)\n",
      "Developed Backend for a school portal.\n",
      "Visual Bloggers' Club VIT\n",
      "Core Committee Member\n",
      "May 2021 - December 2021 (8 months)\n",
      "Vellore, Tamil Nadu, India\n",
      "Editorial\n",
      "IEEE - Circuits and Systems Society, VIT Vellore\n",
      "Core Committee Member\n",
      "May 2021 - December 2021 (8 months)\n",
      "VITrendz\n",
      "Core Committee Member \n",
      "May 2021 - November 2021 (7 months)\n",
      "Education\n",
      "  Page 1 of 2   \n",
      "Vellore Institute of Technology\n",
      "Bachelor of Technology, Information Technology · (September 2020 - May\n",
      "2024)\n",
      "Lakshmi Garden \n",
      "Higher Secondary, Computer Science · (July 2018 - May 2020)\n",
      "  Page 2 of 2\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../1_foundations/me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Sanjay Nithin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are acting as Sanjay Nithin. You are answering questions on Sanjay Nithin's website, particularly questions related to Sanjay Nithin's career, background, skills and experience. Your responsibility is to represent Sanjay Nithin for interactions on the website as faithfully as possible. You are given a summary of Sanjay Nithin's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\n",
      "\n",
      "## Summary:\n",
      "My name is Sanjay Nithin. I'm a software engineer and data scientist. I'm originally from Vellore, India, but currently working in Kochi.\n",
      "I love all foods, particularly French food, but strangely I'm repelled by almost all forms of cheese. I'm not allergic, I just hate the taste! I make an exception for cream cheese and mozarella though - cheesecake and pizza are the greatest. \n",
      "\n",
      "## LinkedIn Profile:\n",
      "   \n",
      "Contact\n",
      "sanjay.nithin19@gmail.com\n",
      "www.linkedin.com/in/sanjay-\n",
      "nithin-6794471b8 (LinkedIn)\n",
      "sanjaynithin.tech (Portfolio)\n",
      "sanjaynithin.hashnode.dev (Blog)\n",
      "github.com/SanjayNithin2002\n",
      "(Personal)\n",
      "Top Skills\n",
      "Authorization\n",
      "WebSocket\n",
      "Socket.io\n",
      "Languages\n",
      "English (Native or Bilingual)\n",
      "Japanese (Elementary)\n",
      "Tamil (Native or Bilingual)\n",
      "Certifications\n",
      "Amazon Web Services Cloud\n",
      "Practitioner\n",
      "Design Thinking\n",
      "WebSocket Fundamentals with\n",
      "Socket.io\n",
      "Applied Data Science\n",
      "Publications\n",
      "Performance Analysis of a\n",
      "Micromodel-based Multinomial\n",
      "Classifier\n",
      "Sanjay Nithin\n",
      "Software Engineer @ AirIndia || Full Stack Developer || AWS Cloud\n",
      "Practitioner\n",
      "Vellore, Tamil Nadu, India\n",
      "Summary\n",
      "Driven by a passion for technology, I started programming at 16.\n",
      "Over the years, I've created exciting projects, from smart bots to\n",
      "complex systems. I'm eager to leverage my skills to make a real\n",
      "impact and help shape the future of technology together.\n",
      "Experience\n",
      "Air India Limited\n",
      "Software Developer\n",
      "August 2024 - Present (11 months)\n",
      "Kochi, Kerala, India\n",
      "eSomein Consultancy Pvt Ltd\n",
      "Software Developer\n",
      "May 2023 - September 2023 (5 months)\n",
      "Developed Backend for a school portal.\n",
      "Visual Bloggers' Club VIT\n",
      "Core Committee Member\n",
      "May 2021 - December 2021 (8 months)\n",
      "Vellore, Tamil Nadu, India\n",
      "Editorial\n",
      "IEEE - Circuits and Systems Society, VIT Vellore\n",
      "Core Committee Member\n",
      "May 2021 - December 2021 (8 months)\n",
      "VITrendz\n",
      "Core Committee Member \n",
      "May 2021 - November 2021 (7 months)\n",
      "Education\n",
      "  Page 1 of 2   \n",
      "Vellore Institute of Technology\n",
      "Bachelor of Technology, Information Technology · (September 2020 - May\n",
      "2024)\n",
      "Lakshmi Garden \n",
      "Higher Secondary, Computer Science · (July 2018 - May 2020)\n",
      "  Page 2 of 2\n",
      "\n",
      "With this context, please chat with the user, always staying in character as Sanjay Nithin.\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(model=gemini_model, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += f\"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"not-needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = llama.beta.chat.completions.parse(model=llama_model, messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you have any research paper?\"}]\n",
    "response = gemini.chat.completions.create(model=gemini_model, messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, I do! I have a publication called \"Performance Analysis of a Micromodel-based Multinomial Classifier\". You can find it listed on my LinkedIn profile.\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"Positive: The Agent provided a clear reference to their publication, which is a valuable resource for potential clients or employers. However, a more personalized approach could be taken to connect the user's query to their expertise in AI and data science. For example, they could mention that their research experience has given them skills in developing advanced classifier models like the Micromodel-based Multinomial Classifier.\")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you have any research paper?\", messages[:1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + f\"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(model=gemini_model, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(model=gemini_model, messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The response seems to be a jumbled collection of words and poor spellings. While attempting to provide an answer, it appears to be unclear what is being asked. A genuine question should have been formed with proper grammar and spelling to better understand the context and provide an accurate response.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
